{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "26037d32-2047-4157-81ef-595916bd66a0"
   },
   "source": [
    "# Checkpoint Three: Cleaning Data\n",
    "\n",
    "Now you are ready to clean your data. Before starting coding, provide the link to your dataset below.\n",
    "\n",
    "My dataset: https://www.kaggle.com/datasets/keremkurt/diversity-equity-and-inclusion-measures-dataset\n",
    "\n",
    "Import the necessary libraries and create your dataframe(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "azdata_cell_guid": "e8adef8e-d0f2-4640-a179-5997f11e82ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 45 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Id                  10000 non-null  int64 \n",
      " 1   Name                10000 non-null  object\n",
      " 2   Surname             10000 non-null  object\n",
      " 3   Division            10000 non-null  object\n",
      " 4   Manager             10000 non-null  object\n",
      " 5   Gender              10000 non-null  object\n",
      " 6   Sexual_Orientation  10000 non-null  object\n",
      " 7   LGBTQ               10000 non-null  object\n",
      " 8   Indigenous          10000 non-null  object\n",
      " 9   Ethnicity           10000 non-null  object\n",
      " 10  Disability          10000 non-null  object\n",
      " 11  Minority            10000 non-null  object\n",
      " 12  Veteran             10000 non-null  object\n",
      " 13  Date of Birth       10000 non-null  object\n",
      " 14  Age                 10000 non-null  int64 \n",
      " 15  Preferred Name      10000 non-null  object\n",
      " 16  Nationality         10000 non-null  object\n",
      " 17  Hobbies             10000 non-null  object\n",
      " 18  Pronouns            10000 non-null  object\n",
      " 19  Mobile Number       10000 non-null  object\n",
      " 20  Email               10000 non-null  object\n",
      " 21  Aug_D_Q1            10000 non-null  int64 \n",
      " 22  Aug_D_Q2            10000 non-null  int64 \n",
      " 23  Aug_D_Q3            10000 non-null  int64 \n",
      " 24  Aug_D_Q4            10000 non-null  int64 \n",
      " 25  Aug_D_Q5            10000 non-null  int64 \n",
      " 26  D_Negative          10000 non-null  int64 \n",
      " 27  D_Neutral           10000 non-null  int64 \n",
      " 28  D_Positive          10000 non-null  int64 \n",
      " 29  Aug_E_Q1            10000 non-null  int64 \n",
      " 30  Aug_E_Q2            10000 non-null  int64 \n",
      " 31  Aug_E_Q3            10000 non-null  int64 \n",
      " 32  Aug_E_Q4            10000 non-null  int64 \n",
      " 33  Aug_E_Q5            10000 non-null  int64 \n",
      " 34  E_Negative          10000 non-null  int64 \n",
      " 35  E_Neutral           10000 non-null  int64 \n",
      " 36  E_Positive          10000 non-null  int64 \n",
      " 37  Aug_I_Q1            10000 non-null  int64 \n",
      " 38  Aug_I_Q2            10000 non-null  int64 \n",
      " 39  Aug_I_Q3            10000 non-null  int64 \n",
      " 40  Aug_I_Q4            10000 non-null  int64 \n",
      " 41  Aug_I_Q5            10000 non-null  int64 \n",
      " 42  I_Negative          10000 non-null  int64 \n",
      " 43  I_Neutral           10000 non-null  int64 \n",
      " 44  I_Positive          10000 non-null  int64 \n",
      "dtypes: int64(26), object(19)\n",
      "memory usage: 3.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Surname</th>\n",
       "      <th>Division</th>\n",
       "      <th>Manager</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Sexual_Orientation</th>\n",
       "      <th>LGBTQ</th>\n",
       "      <th>Indigenous</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>E_Neutral</th>\n",
       "      <th>E_Positive</th>\n",
       "      <th>Aug_I_Q1</th>\n",
       "      <th>Aug_I_Q2</th>\n",
       "      <th>Aug_I_Q3</th>\n",
       "      <th>Aug_I_Q4</th>\n",
       "      <th>Aug_I_Q5</th>\n",
       "      <th>I_Negative</th>\n",
       "      <th>I_Neutral</th>\n",
       "      <th>I_Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Deborah</td>\n",
       "      <td>Addison</td>\n",
       "      <td>IT</td>\n",
       "      <td>No</td>\n",
       "      <td>Transgender</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>No</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mona</td>\n",
       "      <td>Hill</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Kimberly</td>\n",
       "      <td>Shelton</td>\n",
       "      <td>Finance</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Denis</td>\n",
       "      <td>Robinson</td>\n",
       "      <td>HR</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Carmen</td>\n",
       "      <td>Gunn</td>\n",
       "      <td>RD</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id      Name   Surname   Division Manager       Gender Sexual_Orientation  \\\n",
       "0   1   Deborah   Addison         IT      No  Transgender       Heterosexual   \n",
       "1   2      Mona      Hill  Marketing      No         Male       Heterosexual   \n",
       "2   3  Kimberly   Shelton    Finance      No       Female       Heterosexual   \n",
       "3   4     Denis  Robinson         HR      No         Male       Heterosexual   \n",
       "4   5    Carmen      Gunn         RD      No         Male       Heterosexual   \n",
       "\n",
       "               LGBTQ Indigenous Ethnicity  ... E_Neutral E_Positive Aug_I_Q1  \\\n",
       "0  Prefer not to say         No     White  ...         1          2        0   \n",
       "1                 No        Yes     White  ...         2          3        0   \n",
       "2                 No         No     White  ...         0          4       -2   \n",
       "3                 No         No     White  ...         1          3        0   \n",
       "4                 No         No     Asian  ...         0          5        1   \n",
       "\n",
       "  Aug_I_Q2  Aug_I_Q3 Aug_I_Q4 Aug_I_Q5 I_Negative I_Neutral I_Positive  \n",
       "0        1         1        0       -2          1         2          2  \n",
       "1       -1         1        1        0          1         2          2  \n",
       "2        2         2        0        2          1         1          3  \n",
       "3        2         1        0        1          0         2          3  \n",
       "4        1         1        2        2          0         0          5  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Renamed the data set for cleaning. \n",
    "\n",
    "df = pd.read_csv(r\"/Users/Liz/Desktop/Women +/Assignment 4/cleaning-data-checkpoint3/4Clean.csv\")\n",
    "\n",
    "df.shape\n",
    "df.info()\n",
    "df.head()\n",
    "\n",
    "#I can see with the 45 columns that there are several I will want to drop on this clean version\n",
    "#columns 17, 19, and 20 are not relevant from the start. Beyond that, I'll want to explore how\n",
    "#complete the data is in other columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "e172475a-c4ee-414a-8367-9965355dbba6"
   },
   "source": [
    "## Missing Data\n",
    "\n",
    "Test your dataset for missing data and handle it as needed. Make notes in the form of code comments as to your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "azdata_cell_guid": "e1dc66ef-e471-4c27-92e7-ee878c106eba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                    0\n",
       "Name                  0\n",
       "Surname               0\n",
       "Division              0\n",
       "Manager               0\n",
       "Gender                0\n",
       "Sexual_Orientation    0\n",
       "LGBTQ                 0\n",
       "Indigenous            0\n",
       "Ethnicity             0\n",
       "Disability            0\n",
       "Minority              0\n",
       "Veteran               0\n",
       "Date of Birth         0\n",
       "Age                   0\n",
       "Preferred Name        0\n",
       "Nationality           0\n",
       "Pronouns              0\n",
       "Aug_D_Q1              0\n",
       "Aug_D_Q2              0\n",
       "Aug_D_Q3              0\n",
       "Aug_D_Q4              0\n",
       "Aug_D_Q5              0\n",
       "D_Negative            0\n",
       "D_Neutral             0\n",
       "D_Positive            0\n",
       "Aug_E_Q1              0\n",
       "Aug_E_Q2              0\n",
       "Aug_E_Q3              0\n",
       "Aug_E_Q4              0\n",
       "Aug_E_Q5              0\n",
       "E_Negative            0\n",
       "E_Neutral             0\n",
       "E_Positive            0\n",
       "Aug_I_Q1              0\n",
       "Aug_I_Q2              0\n",
       "Aug_I_Q3              0\n",
       "Aug_I_Q4              0\n",
       "Aug_I_Q5              0\n",
       "I_Negative            0\n",
       "I_Neutral             0\n",
       "I_Positive            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the entire set for missing data. \n",
    "#Initially this is a red flag to me that nothing is missing anywhere. This prompts me to \n",
    "#be hypervigilant for the presence of irregular data. \n",
    "df02.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "1233f543-e9a0-4f78-96f5-d7536554102e"
   },
   "source": [
    "## Irregular Data\n",
    "\n",
    "Detect outliers in your dataset and handle them as needed. Use code comments to make notes about your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "azdata_cell_guid": "efed50ae-16f0-471d-98e2-632553a74c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     3 ...  9998  9999 10000]\n",
      "['Deborah' 'Mona' 'Kimberly' 'Denis' 'Carmen' 'Nathan' 'Luke' 'Fred'\n",
      " 'Carter' 'Harry' 'Ramon' 'Nick' 'Kassandra' 'Russel' 'Rhea' 'Liliana'\n",
      " 'Brad' 'David' 'Carina' 'Henry' 'Chester' 'Ronald' 'John' 'Oliver' 'Rosa'\n",
      " 'Fiona' 'Evelynn' 'Nicholas' 'Eduardo' 'Marvin' 'Domenic' 'Lindsay'\n",
      " 'Carissa' 'Jane' 'Jasmine' 'Logan' 'Julianna' 'Emery' 'Gabriel' 'Hannah'\n",
      " 'Chuck' 'Doug' 'Ron' 'Hadley' 'Audrey' 'Tara' 'Mason' 'Percy' 'Liam'\n",
      " 'Joseph' 'Phoebe' 'Jackeline' 'Sienna' 'Marilyn' 'Taylor' 'Mark' 'Hayden'\n",
      " 'Kurt' 'Candice' 'Chelsea' 'Agnes' 'Josh' 'Barney' 'Aiden' 'Noah' 'Clint'\n",
      " 'Ellen' 'Amelia' 'Bob' 'Elijah' 'Ruby' 'Erin' 'Sonya' 'Barry' 'Florence'\n",
      " 'Karen' 'Ethan' 'Enoch' 'Lynn' 'Holly' 'Melinda' 'Matthew' 'Adeline'\n",
      " 'Phillip' 'Abbey' 'Daniel' 'Charlotte' 'Christine' 'Brooklyn' 'Tyler'\n",
      " 'Mike' 'Rick' 'Anne' 'Benjamin' 'Remy' 'Marie' 'Benny' 'Rocco' 'Drew'\n",
      " 'Sage' 'Alan' 'Bart' 'Ciara' 'Robyn' 'Mandy' 'Roger' 'Noemi' 'Ilona'\n",
      " 'Charlize' 'Alexander' 'Daron' 'Michael' 'Zara' 'Jayden' 'Paula'\n",
      " 'Rosalyn' 'Savannah' 'Piper' 'Felicity' 'Rose' 'Leroy' 'Darlene' 'Diane'\n",
      " 'Zoe' 'Camellia' 'Ryan' 'Erica' 'Cameron' 'Anthony' 'Doris' 'Rowan'\n",
      " 'Vanessa' 'Alessandra' 'Karla' 'Josephine' 'Alexia' 'Eve' 'Harmony'\n",
      " 'Destiny' 'Alexa' 'Olivia' 'Hank' 'Anais' 'Carl' 'Kenzie' 'Chanelle'\n",
      " 'Maxwell' 'Grace' 'Ember' 'Rita' 'Aleksandra' 'Sara' 'Teagan' 'Beatrice'\n",
      " 'Adalind' 'Valentina' 'Aileen' 'Vera' 'Maria' 'Susan' 'Kamila' 'Wade'\n",
      " 'Bethany' 'Martin' 'Samantha' 'Sydney' 'Sadie' 'Joyce' 'Emma' 'Tiffany'\n",
      " 'Sarah' 'Jamie' 'Kieth' 'Blake' 'Violet' 'Erick' 'Catherine' 'Gloria'\n",
      " 'Marigold' 'Jack' 'Rufus' 'Owen' 'Johnathan' 'Manuel' 'Gina' 'Andrea'\n",
      " 'Rosalie' 'Abdul' 'Emely' 'Laila' 'Maddison' 'Britney' 'Alba' 'Maribel'\n",
      " 'Elisabeth' 'Vivian' 'Valerie' 'Denny' 'Aisha' 'Chris' 'Willow' 'Javier'\n",
      " 'Rosemary' 'Marissa' 'Camila' 'Adalie' 'Margot' 'Tess' 'Ally' 'Cadence'\n",
      " 'Chad' 'Nicole' 'Melody' 'Dani' 'Jade' 'Selena' 'Boris' 'Cassandra'\n",
      " 'Ivette' 'Analise' 'Colleen' 'Tyson' 'Marjorie' 'Harriet' 'Natalie'\n",
      " 'Sofie' 'Peter' 'Caleb' 'William' 'Cassidy' 'Mavis' 'Margaret' 'Rosie'\n",
      " 'George' 'Courtney' 'Nina' 'Juliette' 'Danny' 'Tony' 'Makenzie' 'Lucy'\n",
      " 'Julian' 'Johnny' 'Bryon' 'Julia' 'Cedrick' 'Alex' 'Quinn' 'Angel' 'Cara'\n",
      " 'Ivy' 'Faith' 'Tom' 'Estrella' 'Norah' 'Mina' 'Aurelia' 'Sebastian'\n",
      " 'Caydence' 'Carrie' 'Ema' 'Daphne' 'Mackenzie' 'Priscilla' 'Daria'\n",
      " 'Summer' 'Isla' 'Jennifer' 'Nate' 'Aeris' 'Jazmin' 'Angela' 'Davina'\n",
      " 'Cristal' 'Isabel' 'Emmanuelle' 'Clarissa' 'Lorraine' 'Bryce' 'Alison'\n",
      " 'Carmella' 'Lara' 'Jacob' 'Gemma' 'Bridget' 'Monica' 'Eileen' 'Rebecca'\n",
      " 'Katelyn' 'Tania' 'Renee' 'Leah' 'Leilani' 'Sharon' 'Jaylene' 'Gwen'\n",
      " 'Moira' 'Madelyn' 'Havana' 'Kirsten' 'Rae' 'Payton' 'Eden' 'Alma' 'Mabel'\n",
      " 'Harvey' 'Miley' 'Alice' 'Gwenyth' 'Michaela' 'Matt' 'Makena' 'Shelby'\n",
      " 'Caitlyn' 'Sloane' 'Belinda' 'Cherish' 'Hope' 'Angelique' 'Bernadette'\n",
      " 'Christy' 'Lillian' 'Georgia' 'Lucas' 'Rachael' 'Andie' 'Francesca'\n",
      " 'Jules' 'Rosalee' 'Ruth' 'Mayleen' 'Anabelle' 'Bristol' 'Esmeralda'\n",
      " 'Hanna' 'Greta' 'Vicky' 'Elly' 'Janice' 'Gil' 'Allison' 'Jocelyn' 'Evie'\n",
      " 'Angelina' 'Gladys' 'Morgan' 'Eryn' 'Rylee' 'Lauren' 'Luna' 'Hazel'\n",
      " 'Stacy' 'Hailey' 'Stella' 'Miriam' 'Dorothy' 'Anabel' 'Dalia' 'Julius'\n",
      " 'Maia' 'Leanne' 'Winnie' 'Callie' 'Crystal' 'Mary' 'Isabella' 'Dasha'\n",
      " 'Michelle' 'Madison' 'Macy' 'Alessia' 'Penelope' 'Adela' 'Lexi' 'Keira'\n",
      " 'Celina' 'Chloe' 'Maya' 'Judith' 'Ada' 'Penny' 'Chadwick' 'Janelle'\n",
      " 'Thea' 'Kendra' 'Carla' 'Rihanna' 'Meredith' 'Sabina' 'Martha' 'Lana'\n",
      " 'Danielle' 'Shannon' 'Leslie' 'Carol' 'Raquel' 'Adina' 'Claire' 'Mya'\n",
      " 'Cynthia' 'Marina' 'Skylar' 'Angelica' 'Sofia' 'Melanie' 'Louise' 'Elise'\n",
      " 'Bree' 'Wendy' 'Cecilia' 'Liv' 'Molly' 'Stephanie' 'Freya' 'Kate' 'Elena'\n",
      " 'Livia' 'Amy' 'Marla' 'Adelaide' 'Sylvia' 'Parker' 'Irene' 'Naomi'\n",
      " 'Celia' 'Jenna' 'Carolyn' 'Helen' 'Juliet' 'Jolene' 'Trisha' 'Goldie'\n",
      " 'Nancy' 'Joy' 'Scarlett' 'Dakota' 'Iris' 'Shay' 'Sasha' 'Kaylee'\n",
      " 'Jessica' 'Melania' 'Peyton' 'Emerald' 'Victoria' 'Regina' 'Camden'\n",
      " 'Megan' 'Elle' 'Samara' 'Lily' 'Jacqueline' 'Mara' 'Maggie' 'Sabrina'\n",
      " 'Paige' 'Candace']\n",
      "['Addison' 'Hill' 'Shelton' 'Robinson' 'Gunn' 'Furnell' 'Sinclair'\n",
      " 'Callan' 'Owen' 'Dobson' 'Mccall' 'Wilton' 'Sloan' 'Jarrett' 'Larsen'\n",
      " 'Latham' 'Todd' 'Windsor' 'Russel' 'Robertson' 'Ainsworth' 'Carson'\n",
      " 'Varley' 'Foxley' 'Underhill' 'Page' 'Hunt' 'Willis' 'Maxwell' 'Cadman'\n",
      " 'Holmes' 'Allcott' 'Redfern' 'Michael' 'Yang' 'Roberts' 'King' 'Boyle'\n",
      " 'Waterhouse' 'Ingham' 'Rixon' 'Booth' 'Ellery' 'Goldsmith' 'Tyrrell'\n",
      " 'Jeffery' 'Heaton' 'Clifford' 'Allington' 'Kennedy' 'Potts' 'Farrell'\n",
      " 'Bolton' 'Dallas' 'Farrant' 'Santos' 'Gosling' 'Knight' 'Phillips'\n",
      " 'Stone' 'Edwards' 'Patel' 'Mitchell' 'Baker' 'Wigley' 'Addis' 'Graham'\n",
      " 'Wright' 'Irwin' 'Price' 'Spencer' 'Yarwood' 'Wilkinson' 'Ellison'\n",
      " 'Zaoui' 'Simpson' 'Coleman' 'Murray' 'Evans' 'Fall' 'Blackwall' 'Watson'\n",
      " 'Avery' 'Hood' 'Andrews' 'Amstead' 'Quinton' 'Gilmore' 'Bishop' 'Weldon'\n",
      " 'London' 'Williams' 'Wallace' 'Plumb' 'Khan' 'Olivier' 'Harper' 'Moss'\n",
      " 'Payne' 'Chappell' 'Cork' 'Hastings' 'Mcgee' 'Tyler' 'Parr' 'Button'\n",
      " 'Higgs' 'Potter' 'Brown' 'Moore' 'Garcia' 'Drummond' 'Kelly' 'Dann'\n",
      " 'Jarvis' 'Gray' 'Ellis' 'Morrow' 'Whittle' 'Mullins' 'Neville' 'Ward'\n",
      " 'Palmer' 'Kent' 'Freeburn' 'Stevens' 'Rivers' 'Collins' 'Lowe' 'Gibson'\n",
      " 'Bradshaw' 'Harrington' 'Umney' 'Noon' 'Tennant' 'Hopkins' 'Selby'\n",
      " 'Richards' 'Cooper' 'Welsch' 'Saunders' 'Thatcher' 'Bailey' 'Parsons'\n",
      " 'Harrison' 'Chester' 'Harvey' 'Cowan' 'Weasley' 'Niles' 'West' 'Wren'\n",
      " 'Stuart' 'Ashwell' 'Glass' 'Thomson' 'Shaw' 'Thompson' 'Jones' 'James'\n",
      " 'Chadwick' 'Ashley' 'Yarlett' 'Abbot' 'Parker' 'Bingham' 'Fowler'\n",
      " 'Mcguire' 'Verdon' 'Mcleod' 'Barrett' 'Leslie' 'Grant' 'Becker' 'Watt'\n",
      " 'Benfield' 'Walker' 'Gordon' 'Milner' 'Russell' 'Curtis' 'Denton'\n",
      " 'Edmonds' 'Steer' 'Pierce' 'Davies' 'Emmott' 'Seymour' 'Nielson' 'Morris'\n",
      " 'Hobbs' 'Dubois' 'Norburn' 'Reese' 'Uttley' 'Doherty' 'Clark' 'Lindop'\n",
      " 'Ulyatt' 'Swan' 'Roth' 'Hall' 'Shepherd' 'Horton' 'Uttridge' 'Wilcox'\n",
      " 'Beal' 'Purvis' 'Newton' 'Jacobs' 'Hopkinson' 'Noach' 'Grady' 'Crawford'\n",
      " 'Bradley' 'Yard' 'Pope' 'Carter' 'Hepburn' 'Emmett' 'Redwood' 'Mooney'\n",
      " 'Ellwood' 'Walter' 'Boden' 'Rehman' 'Thorpe' 'Uddin' 'Snell' 'Swift'\n",
      " 'Randall' 'Greenwood' 'Kaur' 'Bullock' 'Raven' 'Lloyd' 'Cavanagh' 'Lynn'\n",
      " 'Stewart' 'Clarke' 'Tailor' 'Bennett' 'Reynolds' 'Sawyer' 'Vaughn'\n",
      " 'Dyson' 'Nicholls' 'Brett' 'Wellington' 'Eastwood' 'Butler' 'Forth'\n",
      " 'Rainford' 'Larkin' 'Ebden' 'Willson' 'Styles' 'Isaac' 'Vane' 'Lee'\n",
      " 'Connor' 'Matthews' 'Dempsey' 'Ebbs' 'Devonport' 'Moreno' 'Squire'\n",
      " 'Tanner' 'Adler' 'Judd' 'Hobson' 'Emerson' 'Sherry' 'Alcroft' 'Casey'\n",
      " 'Donovan' 'Lunt' 'Partridge' 'Buckley' 'Mills' 'Douglas' 'Oliver' 'Shea'\n",
      " 'Forester' 'Power' 'Porter' 'Gavin' 'Fenton' 'Thorne' 'Holt' 'Ring'\n",
      " 'Donnelly' 'Ventura' 'Summers' 'Allwood' 'Faulkner' 'Bell' 'Thomas'\n",
      " 'White' 'Bryson' 'Dickson' 'Archer' 'Walton' 'Hunter' 'Smith' 'Benson'\n",
      " 'Eaton' 'Griffiths' 'Tutton' 'Flynn' 'Gregory' 'Newman' 'Turner'\n",
      " 'Hancock' 'Durrant' 'Rees' 'Driscoll' 'Young' 'Alldridge' 'Everett'\n",
      " 'Terry' 'Vinton' 'Harris' 'Moran' 'Eyres' 'Darcy' 'Richardson' 'Ranks'\n",
      " 'Gaynor' 'Sheldon' 'Middleton' 'Preston' 'Cann' 'Mason' 'Samuel' 'Oakley'\n",
      " 'Walsh' 'Gardner' 'Clifton' 'Taylor' 'Morrison' 'Pitt' 'Rycroft'\n",
      " 'Johnson' 'Martin' 'Locke' 'Ianson' 'Weston' 'Shields' 'Osman' 'Norris'\n",
      " 'Neal' 'Groves' 'Jenkin' 'Poulton' 'Quinnell' 'Marshall' 'Jackson'\n",
      " 'Janes' 'Whitehouse' 'Aldridge' 'Rose' 'Mackenzie' 'Wise' 'Little'\n",
      " 'Hammond' 'Hope' 'Lane' 'Leigh' 'Camden' 'Myatt' 'Franks' 'Carpenter'\n",
      " 'Veale' 'Lucas' 'Hooper' 'Jefferson' 'Asher' 'Coates' 'Glynn' 'Gates'\n",
      " 'Lindsay' 'Ross' 'Burnley' 'Malone' 'Corbett' 'Connell' 'Wilson' 'Dowson'\n",
      " 'Collis' 'Huggins' 'Jordan' 'Redden' 'Oswald' 'Robe' 'Reyes' 'Jenkins'\n",
      " 'Drake' 'Whitmore' 'Keys' 'Roman' 'Pickard' 'Truscott' 'Snow' 'Campbell'\n",
      " 'Coll' 'Powell' 'Rowlands' 'Stark' 'Farrow' 'Quinn' 'Tait' 'Norman'\n",
      " 'Sylvester' 'Howard' 'Kidd' 'Gilbert' 'Tobin' 'Dale' 'Goodman' 'Whatson'\n",
      " 'Bayliss' 'Ballard' 'Brennan' 'Ogilvy' 'Mould' 'Ramsey' 'Kirby' 'Exton'\n",
      " 'Collingwood' 'Ripley' 'Stubbs' 'Armstrong' 'Flanders' 'Upton' 'Knott'\n",
      " 'Healy' 'Talbot' 'Bentley' 'Dillon' 'Mcneill' 'Victor' 'Addley' 'Cattell'\n",
      " 'Scott' 'Brooks' 'Chapman' 'Fields' 'Irving' 'Poole' 'Anderson' 'Overson'\n",
      " 'Appleton' 'Wade' 'Widdows' 'Radley' 'Nayler' 'Radcliffe' 'Crawley'\n",
      " 'Speed' 'Woodley' 'Needham' 'Savage' 'Fleming' 'Upsdell' 'Briggs' 'Penn'\n",
      " 'Oldfield' 'Tindall' 'Hardwick' 'Hewitt' 'Calderwood' 'Olson' 'Hogg'\n",
      " 'Bristow' 'Rodwell' 'Nash' 'Ingram' 'Villiger' 'Clarkson' 'Jennson'\n",
      " 'Alexander' 'Rothwell' 'Hale' 'Blythe' 'Craig' 'Farmer' 'Pratt' 'Osmond'\n",
      " 'Sanchez' 'Ryan' 'Jobson' 'Lynch' 'Wheeler' 'Paterson' 'Mann' 'Gibbons'\n",
      " 'May' 'Egerton' 'Giles' 'Townend' 'Strong' 'Warden' 'Waterson' 'Brock'\n",
      " 'Dixon' 'Nanton' 'Nicolas' 'Lewis' 'Cunningham' 'Cartwright' 'Murphy'\n",
      " 'Stanton' 'Clayton' 'Mccormick' 'Ralph' 'Rigg' 'Torres' 'Nurton' 'Roscoe'\n",
      " 'Bowen' 'Riley' 'Morgan' 'Gallacher' 'Daniells' 'Bloom' 'Atkinson' 'Rust'\n",
      " 'Lakey' 'Vangness' 'Rosenbloom' 'Hilton' 'Cox' 'Vincent' 'Vernon'\n",
      " 'Haines' 'Cameron' 'Stevenson' 'Varndell' 'Pond' 'Wood' 'Nelson' 'Pearce'\n",
      " 'Wooldridge' 'Attwood' 'Woods' 'Grey' 'Abbey' 'Bright' 'Weatcroft'\n",
      " 'Adams' 'York' 'Rowan' 'Hamilton' 'Reading' 'Sherwood' 'Warren' 'Vollans'\n",
      " 'Slater' 'Miller' 'Edler' 'Henderson' 'Whinter' 'Fox' 'Allen' 'Dwyer'\n",
      " 'Blackburn' 'Rogan' 'Baldwin' 'Trent' 'Rogers' 'Logan' 'Rodgers' 'Kerr'\n",
      " 'Rossi' 'Hudson' 'Mcnally' 'Wills' 'Bryant' 'Yates' 'Skinner' 'Drew'\n",
      " 'Vallory' 'Simmons' 'Nobbs' 'Lyon' 'Andersson' 'Flack' 'Eagle' 'Vince'\n",
      " 'Notman' 'Lambert' 'Vass' 'Stanley' 'Wilde' 'Edley' 'Antcliff' 'Plant'\n",
      " 'Silva' 'Baxter' 'Salt' 'Reid' 'Morley' 'Herbert' 'Garner' 'Wild'\n",
      " 'Graves' 'Lewin' 'Funnell' 'Cobb' 'John' 'Webster' 'Cassidy' 'Vallins'\n",
      " 'Broomfield' 'Yoman' 'Dunbar' 'Vaughan' 'Tate' 'Utterson' 'Oatway'\n",
      " 'Barclay' 'Lomax' 'Norton' 'Gilmour' 'Fisher' 'Downing' 'Pearson' 'Burge'\n",
      " 'Duvall' 'Mcgregor' 'Woodcock' 'Gonzales' 'Warner' 'Flett' 'Long' 'Owens'\n",
      " 'Thornton' 'Eddison' 'Fulton' 'Rowe']\n",
      "['IT' 'Marketing' 'Finance' 'HR' 'RD' 'Sales' 'Operations']\n",
      "['No' 'Yes']\n",
      "['Transgender' 'Male' 'Female' 'Prefer not to say'\n",
      " 'Non-binary/non-conforming' 'Other']\n",
      "['Heterosexual' 'Prefer not to say' 'Bisexual' 'Homosexual' 'Other']\n",
      "['Prefer not to say' 'No' 'Yes']\n",
      "['No' 'Yes' 'Prefer not to say']\n",
      "['White' 'Asian' 'Black' 'Middle Eastern' 'Other' 'Latin'\n",
      " 'Prefer not to say']\n",
      "['Yes' 'No' 'Prefer not to say']\n",
      "['No' 'Yes' 'Prefer not to say']\n",
      "['No' 'Prefer not to say' 'Yes']\n",
      "['1993-06-04' '1963-08-02' '1979-04-25' ... '1990-03-21' '1987-08-04'\n",
      " '1960-04-27']\n",
      "[29 59 43 44 50 37 34 27 52 47 54 35 32 39 33 40 26 30 36 28 49 31 41 45\n",
      " 56 42 25 58 57 65 38 48 53 46 64 60 62 55 63 51 61 24]\n",
      "['Deborah' 'Mona' 'Kimberly' 'Denis' 'Carmen' 'Nathan' 'Luke' 'Fred'\n",
      " 'Carter' 'Harry' 'Ramon' 'Nick' 'Kassandra' 'Russel' 'Rhea' 'Liliana'\n",
      " 'Brad' 'David' 'Carina' 'Henry' 'Chester' 'Ronald' 'John' 'Oliver' 'Rosa'\n",
      " 'Fiona' 'Evelynn' 'Nicholas' 'Eduardo' 'Marvin' 'Domenic' 'Lindsay'\n",
      " 'Carissa' 'Jane' 'Jasmine' 'Logan' 'Julianna' 'Emery' 'Gabriel' 'Hannah'\n",
      " 'Chuck' 'Doug' 'Ron' 'Hadley' 'Audrey' 'Tara' 'Mason' 'Percy' 'Liam'\n",
      " 'Joseph' 'Phoebe' 'Jackeline' 'Sienna' 'Marilyn' 'Taylor' 'Mark' 'Hayden'\n",
      " 'Kurt' 'Candice' 'Chelsea' 'Agnes' 'Josh' 'Barney' 'Aiden' 'Noah' 'Clint'\n",
      " 'Ellen' 'Amelia' 'Bob' 'Elijah' 'Ruby' 'Erin' 'Sonya' 'Barry' 'Florence'\n",
      " 'Karen' 'Ethan' 'Enoch' 'Lynn' 'Holly' 'Melinda' 'Matthew' 'Adeline'\n",
      " 'Phillip' 'Abbey' 'Daniel' 'Charlotte' 'Christine' 'Brooklyn' 'Tyler'\n",
      " 'Mike' 'Rick' 'Anne' 'Benjamin' 'Remy' 'Marie' 'Benny' 'Rocco' 'Drew'\n",
      " 'Sage' 'Alan' 'Bart' 'Ciara' 'Robyn' 'Mandy' 'Roger' 'Noemi' 'Ilona'\n",
      " 'Charlize' 'Alexander' 'Daron' 'Michael' 'Zara' 'Jayden' 'Paula'\n",
      " 'Rosalyn' 'Savannah' 'Piper' 'Felicity' 'Rose' 'Leroy' 'Darlene' 'Diane'\n",
      " 'Zoe' 'Camellia' 'Ryan' 'Erica' 'Cameron' 'Anthony' 'Doris' 'Rowan'\n",
      " 'Vanessa' 'Alessandra' 'Karla' 'Josephine' 'Alexia' 'Eve' 'Harmony'\n",
      " 'Destiny' 'Alexa' 'Olivia' 'Hank' 'Anais' 'Carl' 'Kenzie' 'Chanelle'\n",
      " 'Maxwell' 'Grace' 'Ember' 'Rita' 'Aleksandra' 'Sara' 'Teagan' 'Beatrice'\n",
      " 'Adalind' 'Valentina' 'Aileen' 'Vera' 'Maria' 'Susan' 'Kamila' 'Wade'\n",
      " 'Bethany' 'Martin' 'Samantha' 'Sydney' 'Sadie' 'Joyce' 'Emma' 'Tiffany'\n",
      " 'Sarah' 'Jamie' 'Kieth' 'Blake' 'Violet' 'Erick' 'Catherine' 'Gloria'\n",
      " 'Marigold' 'Jack' 'Rufus' 'Owen' 'Johnathan' 'Manuel' 'Gina' 'Andrea'\n",
      " 'Rosalie' 'Abdul' 'Emely' 'Laila' 'Maddison' 'Britney' 'Alba' 'Maribel'\n",
      " 'Elisabeth' 'Vivian' 'Valerie' 'Denny' 'Aisha' 'Chris' 'Willow' 'Javier'\n",
      " 'Rosemary' 'Marissa' 'Camila' 'Adalie' 'Margot' 'Tess' 'Ally' 'Cadence'\n",
      " 'Chad' 'Nicole' 'Melody' 'Dani' 'Jade' 'Selena' 'Boris' 'Cassandra'\n",
      " 'Ivette' 'Analise' 'Colleen' 'Tyson' 'Marjorie' 'Harriet' 'Natalie'\n",
      " 'Sofie' 'Peter' 'Caleb' 'William' 'Cassidy' 'Mavis' 'Margaret' 'Rosie'\n",
      " 'George' 'Courtney' 'Nina' 'Juliette' 'Danny' 'Tony' 'Makenzie' 'Lucy'\n",
      " 'Julian' 'Johnny' 'Bryon' 'Julia' 'Cedrick' 'Alex' 'Quinn' 'Angel' 'Cara'\n",
      " 'Ivy' 'Faith' 'Tom' 'Estrella' 'Norah' 'Mina' 'Aurelia' 'Sebastian'\n",
      " 'Caydence' 'Carrie' 'Ema' 'Daphne' 'Mackenzie' 'Priscilla' 'Daria'\n",
      " 'Summer' 'Isla' 'Jennifer' 'Nate' 'Aeris' 'Jazmin' 'Angela' 'Davina'\n",
      " 'Cristal' 'Isabel' 'Emmanuelle' 'Clarissa' 'Lorraine' 'Bryce' 'Alison'\n",
      " 'Carmella' 'Lara' 'Jacob' 'Gemma' 'Bridget' 'Monica' 'Eileen' 'Rebecca'\n",
      " 'Katelyn' 'Tania' 'Renee' 'Leah' 'Leilani' 'Sharon' 'Jaylene' 'Gwen'\n",
      " 'Moira' 'Madelyn' 'Havana' 'Kirsten' 'Rae' 'Payton' 'Eden' 'Alma' 'Mabel'\n",
      " 'Harvey' 'Miley' 'Alice' 'Gwenyth' 'Michaela' 'Matt' 'Makena' 'Shelby'\n",
      " 'Caitlyn' 'Sloane' 'Belinda' 'Cherish' 'Hope' 'Angelique' 'Bernadette'\n",
      " 'Christy' 'Lillian' 'Georgia' 'Lucas' 'Rachael' 'Andie' 'Francesca'\n",
      " 'Jules' 'Rosalee' 'Ruth' 'Mayleen' 'Anabelle' 'Bristol' 'Esmeralda'\n",
      " 'Hanna' 'Greta' 'Vicky' 'Elly' 'Janice' 'Gil' 'Allison' 'Jocelyn' 'Evie'\n",
      " 'Angelina' 'Gladys' 'Morgan' 'Eryn' 'Rylee' 'Lauren' 'Luna' 'Hazel'\n",
      " 'Stacy' 'Hailey' 'Stella' 'Miriam' 'Dorothy' 'Anabel' 'Dalia' 'Julius'\n",
      " 'Maia' 'Leanne' 'Winnie' 'Callie' 'Crystal' 'Mary' 'Isabella' 'Dasha'\n",
      " 'Michelle' 'Madison' 'Macy' 'Alessia' 'Penelope' 'Adela' 'Lexi' 'Keira'\n",
      " 'Celina' 'Chloe' 'Maya' 'Judith' 'Ada' 'Penny' 'Chadwick' 'Janelle'\n",
      " 'Thea' 'Kendra' 'Carla' 'Rihanna' 'Meredith' 'Sabina' 'Martha' 'Lana'\n",
      " 'Danielle' 'Shannon' 'Leslie' 'Carol' 'Raquel' 'Adina' 'Claire' 'Mya'\n",
      " 'Cynthia' 'Marina' 'Skylar' 'Angelica' 'Sofia' 'Melanie' 'Louise' 'Elise'\n",
      " 'Bree' 'Wendy' 'Cecilia' 'Liv' 'Molly' 'Stephanie' 'Freya' 'Kate' 'Elena'\n",
      " 'Livia' 'Amy' 'Marla' 'Adelaide' 'Sylvia' 'Parker' 'Irene' 'Naomi'\n",
      " 'Celia' 'Jenna' 'Carolyn' 'Helen' 'Juliet' 'Jolene' 'Trisha' 'Goldie'\n",
      " 'Nancy' 'Joy' 'Scarlett' 'Dakota' 'Iris' 'Shay' 'Sasha' 'Kaylee'\n",
      " 'Jessica' 'Melania' 'Peyton' 'Emerald' 'Victoria' 'Regina' 'Camden'\n",
      " 'Megan' 'Elle' 'Samara' 'Lily' 'Jacqueline' 'Mara' 'Maggie' 'Sabrina'\n",
      " 'Paige' 'Candace']\n",
      "['Polish' 'Lao' 'Canadian' 'Korean' 'English' 'Norwegian' 'Indian'\n",
      " 'Jordanian' 'Sri Lankan' 'British' 'Brazilian' 'American' 'Ukrainian'\n",
      " 'Mongolian' 'Malaysian' 'Chinese' 'Greek' 'Australian' 'Afghan'\n",
      " 'Icelandic' 'Costa Rican' 'Czech' 'Fijian' 'Moroccan' 'Bangladeshi'\n",
      " 'Hungarian' 'Colombian' 'Dominican' 'Zambian' 'Lebanese' 'Scottish'\n",
      " 'Latvian' 'Peruvian' 'Vietnamese' 'Nigerian' 'Russian' 'German' 'Chilean'\n",
      " 'Indonesian' 'Taiwanese' 'Cuban' 'Uruguayan' 'Guatemalan' 'Spanish'\n",
      " 'Thai' 'Japanese' 'Namibian' 'Danish' 'Irish' 'Malagasy' 'Bolivian'\n",
      " 'Honduran' 'Austrian' 'Romanian' 'Philippine' 'Dutch' 'South African'\n",
      " 'Batswana' 'Lithuanian' 'Venezuelan' 'Ghanaian' 'Iraqi' 'Jamaican'\n",
      " 'Paraguayan' 'Tongan' 'Libyan' 'Kuwaiti' 'Argentinian' 'Ecuadorian'\n",
      " 'Nepalese' 'Singaporean' 'French' 'Zimbabwean' 'Mozambican' 'Tunisian'\n",
      " 'Nicaraguan' 'Egyptian' 'Mexican' 'Belgian' 'Kenyan' 'Croatian'\n",
      " 'Bulgarian' 'Slovak' 'Turkish' 'Tajikistani' 'Estonian' 'New Zealand'\n",
      " 'Maltese' 'Cambodian' 'Algerian' 'Cameroonian' 'Panamanian' 'Haitian'\n",
      " 'Pakistani' 'Salvadorian' 'Finnish' 'Ethiopian' 'Swedish' 'Syrian'\n",
      " 'Saudi' 'Welsh' 'Emirati' 'Serbian' 'Sudanese' 'Swiss' 'Israeli'\n",
      " 'Albanian' 'Senegalese' 'Portuguese' 'Italian' 'Malian' 'Iranian']\n",
      "['Travelling' 'Reading' 'Sports' 'Cooking' 'Music' 'Video Games'\n",
      " 'Crafting' 'Fishing']\n",
      "['They/them/theirs' 'He/him/his' 'She/her/hers' 'Ze/hir/hirs' 'E/em/eirs'\n",
      " 'Ze/zir/zirs' 'Xe/xem/xyrs']\n",
      "['363 436 1096' '905 980 9989' '788 356 1577' ... '695 929 9404'\n",
      " '821 130 2328' '181 174 9542']\n",
      "['Deborah.Addison@mail.ca' 'Mona.Hill@mail.ca' 'Kimberly.Shelton@mail.ca'\n",
      " ... 'Abbey.Randall@mail.ca' 'Benny.Abbot@mail.ca' 'Olivia.Denton@mail.ca']\n",
      "[-1 -2  0  2  1]\n",
      "[ 2 -1  0  1 -2]\n",
      "[-1  0 -2  1  2]\n",
      "[ 0  2 -1  1 -2]\n",
      "[-2  2  1  0 -1]\n",
      "[3 1 2 4 0 5]\n",
      "[1 2 0 3 4 5]\n",
      "[1 3 2 4 0 5]\n",
      "[ 0  2  1 -1 -2]\n",
      "[-1  2  1 -2  0]\n",
      "[ 1  0  2 -2 -1]\n",
      "[-2  2 -1  0  1]\n",
      "[ 1  0  2 -2 -1]\n",
      "[2 0 1 3 4 5]\n",
      "[1 2 0 3 4 5]\n",
      "[2 3 4 5 1 0]\n",
      "[ 0 -2  1 -1  2]\n",
      "[ 1 -1  2 -2  0]\n",
      "[ 1  2 -2  0 -1]\n",
      "[ 0  1  2 -1 -2]\n",
      "[-2  0  2  1 -1]\n",
      "[1 0 3 4 2 5]\n",
      "[2 1 0 4 3 5]\n",
      "[2 3 5 4 1 0]\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(df[col].unique())\n",
    "    \n",
    "#It would be interesting to see how many columns had a different given name vs preferred name.\n",
    "#I'm thinking this is something I could better run on SQL. I'm definitely interested in the numbers of \n",
    "#'Prefer Not To Say' in several columns. It will be interesting to see if there are correlatins with \n",
    "#other data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "6f5b8ee0-bab3-44bc-958a-67d1e4c0407f"
   },
   "source": [
    "## Unnecessary Data\n",
    "\n",
    "Look for the different types of unnecessary data in your dataset and address it as needed. Make sure to use code comments to illustrate your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "azdata_cell_guid": "e788a239-2fbf-41de-9bd3-19e52e3b187c"
   },
   "outputs": [],
   "source": [
    "#These columns are not relevant to the business question. \n",
    "df02 = df.drop(['Hobbies','Mobile Number','Email'], axis = 1)\n",
    "\n",
    "#I'm not certain there is much benefit to keeping both the birthday and age columns. I need to check to see if\n",
    "#there are issues there (ex the age is not correct per the birthday), otherwise, I don't \n",
    "#see needing both to address my visualization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "53e0cf94-c68a-4fa0-9849-9505a66bcce6"
   },
   "source": [
    "## Inconsistent Data\n",
    "\n",
    "Check for inconsistent data and address any that arises. As always, use code comments to illustrate your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "azdata_cell_guid": "e9de6624-812a-43f8-8e20-93b4a49b091f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male                         5902\n",
      "Female                       3388\n",
      "Prefer not to say             397\n",
      "Non-binary/non-conforming     110\n",
      "Other                         106\n",
      "Transgender                    97\n",
      "Name: Gender, dtype: int64\n",
      "Heterosexual         8406\n",
      "Prefer not to say     972\n",
      "Homosexual            407\n",
      "Other                 112\n",
      "Bisexual              103\n",
      "Name: Sexual_Orientation, dtype: int64\n",
      "No                   8177\n",
      "Yes                  1175\n",
      "Prefer not to say     648\n",
      "Name: LGBTQ, dtype: int64\n",
      "No                   7694\n",
      "Yes                  2206\n",
      "Prefer not to say     100\n",
      "Name: Minority, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "df02.head(5)\n",
    "\n",
    "print(df02['Gender'].value_counts())\n",
    "print(df02['Sexual_Orientation'].value_counts())\n",
    "print(df02['LGBTQ'].value_counts())\n",
    "print(df02['Minority'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "dedc0bfe-17d0-40b2-914f-2ddb54f9ce0d"
   },
   "source": [
    "## Summarize Your Results\n",
    "\n",
    "Make note of your answers to the following questions.\n",
    "\n",
    "1. Did you find all four types of dirty data in your dataset? I did not find missing or inconsistent data. \n",
    "2. Did the process of cleaning your data give you new insights into your dataset? Yes. From my previous analysis, I am concerned about employee privacy as this is not an anonoymous data set and some of these questions are quite personal. I am interested to know why some employees answered \"Prefer Not To Say\" while some selected \"Other.\" In most categories, there are a small number of answers compared to the full data set, but I think that's the point of this data. Also, in the \"Minority\" column, is the employee deciding if they identify as a minority? In what sense? Ethnic, racial, gender, sexual orientation. I cannot see the question, so I'm not certain tha this column is useful for my purposes. \n",
    "3. Is there anything you would like to make note of when it comes to manipulating the data and making visualizations?\n",
    "I want to make sure I compare things in an meanigful way. As I started to pay around with charts, I don't think that it makes sense to compare certain points (LGBTQ to Gender). I believe it is more helpful to the business question to instead compare these columns to departments, management numbers, etc. \n",
    "\n",
    "Additionally, I think it is critical to develop a simple way to visualize diversity, equity, and inclusion separately and collectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
